# ğŸ“˜ Assignment 2: Supervised Learning â€“ Support Vector Machine (SVM)
 
## ğŸ‘¥ Group Assignment  
This assignment explores the **Support Vector Machine (SVM)** algorithm using the **WorkhoursProductivity** dataset to enable a direct performance comparison.
 
---
 
## ğŸ§  Part 1: Familiarization and Basic Testing of SVM 
 
### ğŸ“Š Dataset Selection 
- We used the **WorkhoursProductivity** dataset.
- This allowed us to directly compare **kNN vs. SVM** performance under similar conditions.
- The dataset contains labeled data suitable for supervised classification.
 
---
 
### âš™ï¸ Algorithm Application 
- Implemented SVM using **`sklearn.svm.SVC`**.
- Tested multiple kernels to observe performance differences:
  - ğŸ”¹ **Linear Kernel**
  - ğŸ”¹ **Polynomial Kernel**
- The model was trained and evaluated using standard train-test splits.
 
---
 
### ğŸŒ Real-World Applications of SVM 
Support Vector Machines are highly effective in **high-dimensional spaces**, making them suitable for:
 
1. ğŸ“° **Text Classification**  
   - Spam detection  
   - Sentiment analysis  
   - Document categorization  
 
2. ğŸ§¬ **Bioinformatics**  
   - Gene classification  
   - Cancer detection using high-dimensional medical data  
 
---
 
## ğŸ”¬ Part 2: In-Depth Experimentation with SVM 
 
### ğŸ›ï¸ Parameter Experimentation 
- Experimented with different values of **C (regularization parameter)**:
  - Low C â†’ More regularization, simpler decision boundary
  - High C â†’ Less regularization, more complex boundary
- Observed that:
  - âš ï¸ Very high C may cause overfitting
  - âœ… Moderate C values provided better generalization
 
---
 
### ğŸ” Kernel Comparison 
We compared at least two kernels on the same dataset:
 
| Kernel Type | Observations |
|------------|--------------|
| **Linear** | Faster training, works well when data is linearly separable |
| **Polynomial** | Captures non-linear patterns but may overfit with higher degrees |
 
---
 
## ğŸ“ˆ Findings & Observations âœ…
 
- ğŸ†š **SVM generally performed better than kNN** on this dataset, especially with optimal parameter tuning.
- ğŸ§© **Kernel choice significantly impacts performance**:
  - Linear kernel worked well for simpler patterns
  - Polynomial kernel improved accuracy for non-linear relationships
- ğŸ¯ SVM is more **robust to high-dimensional data** compared to kNN.
- âš–ï¸ Proper tuning of **C** is critical to balance bias and variance.
 
---
 
## ğŸ› ï¸ Tools & Libraries Used
- ğŸ Python
- ğŸ“¦ Scikit-learn
- ğŸ“Š NumPy
- ğŸ“ˆ Matplotlib / Seaborn (for visualization)
 
---
 
## ğŸ“Œ Conclusion
SVM is a powerful supervised learning algorithm that:
- Excels in high-dimensional spaces
- Offers flexibility through kernel functions
- Often outperforms distance-based methods like kNN when properly tuned
 
This assignment demonstrates how **parameter tuning and kernel selection** directly influence SVM performance.
 
